{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc772d0-743b-4ab7-9713-9c835494492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd45cb2-55e7-47b8-947d-df4ef4809d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple linear regression uses one independent variable to predict a dependent variable. \n",
    "#Multiple linear regression uses multiple independent variables to predict a dependent variable.\n",
    "\n",
    "#For example, simple linear regression could be used to predict the price of a house based on its square footage. \n",
    "#Multiple linear regression could be used to predict the price of a house based on its square footage, number of bedrooms, and number of bathrooms.\n",
    "\n",
    "#In other words, simple linear regression is a one-variable model, while multiple linear regression is a multi-variable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0986df0-c897-4482-928f-0d5e1d2f5dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "#a given dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e643ec8-4b84-4025-b71f-a44ee2d196d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The assumptions of linear regression are:\n",
    "\n",
    "Linearity: The relationship between the independent variable(s) and the dependent variable is linear. \n",
    "This can be checked by plotting the data and looking for a straight-line relationship.\n",
    "Homoscedasticity: The variance of the residuals is constant across all values of the independent variable(s).\n",
    "This can be checked by plotting the residuals against the predicted values and looking for a constant variance.\n",
    "Normality: The residuals are normally distributed. This can be checked by plotting the residuals and looking for a bell-shaped distribution.\n",
    "Independence: The residuals are independent of each other. This can be checked by plotting the residuals against the order of the observations and looking for any patterns.\n",
    "Multicollinearity: The independent variables are not highly correlated with each other. This can be checked by calculating the correlation matrix of the independent variables.\n",
    "\n",
    "Here are some ways to check whether these assumptions hold in a given dataset:\n",
    "\n",
    "Linearity: You can plot the data and look for a straight-line relationship. We can also use statistical tests such as the Durbin-Watson test and the Goldfeld-Quandt test.\n",
    "Homoscedasticity: You can plot the residuals against the predicted values and look for a constant variance.\n",
    "We can also use statistical tests such as the Breusch-Pagan test and the White test.\n",
    "Normality: You can plot the residuals and look for a bell-shaped distribution. We can also use statistical tests such as the Shapiro-Wilk test and the Kolmogorov-Smirnov test.\n",
    "Independence: You can plot the residuals against the order of the observations and look for any patterns. We can also use statistical tests such as the Durbin-Watson test.\n",
    "Multicollinearity: We can calculate the correlation matrix of the independent variables and look for any pairs of variables that are highly correlated.\n",
    "We can also use statistical tests such as the variance inflation factor (VIF).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780188e5-7892-461d-9579-ae566f32b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6850e456-99e3-4508-940f-db4616276278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The slope of a linear regression model tells you how much the dependent variable changes for every unit change in the independent variable.\n",
    "#The intercept tells you the value of the dependent variable when the independent variable is zero.\n",
    "\n",
    "#In this real-world scenario, the slope of the model might be 100, which means that the price of the house increases by 100 for every additional square foot of space. \n",
    "#The intercept might be 100,000, which means that the price of a house with zero square footage is 100,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2888088-71cf-4694-93a3-5854d021eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75faa57-b891-4ca0-a0a8-f0ba0a129469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Gradient descent is an optimization algorithm that finds the minimum of a function. It is used in machine learning to find the parameters of a model that minimize a cost function.\n",
    "\n",
    "The steps of gradient descent are:\n",
    "\n",
    "Start with an initial guess for the parameters.\n",
    "Update the parameters in the direction of the negative gradient of the cost function.\n",
    "Repeat until the cost function converges to a minimum.\n",
    "\n",
    "Here are some examples of how gradient descent is used in machine learning:\n",
    "\n",
    "Linear regression: Gradient descent is used to find the parameters of a linear regression model. The cost function in linear regression is the sum of the squared residuals.\n",
    "Logistic regression: Gradient descent is used to find the parameters of a logistic regression model. The cost function in logistic regression is the cross-entropy loss.\n",
    "Support vector machines: Gradient descent is used to find the parameters of a support vector machine model. The cost function in support vector machines is the hinge loss.\n",
    "Neural networks: Gradient descent is used to find the parameters of a neural network model. The cost function in neural networks is typically the cross-entropy loss.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adbfa8a-4207-4052-93dc-6d2189f1d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64d79f5-175f-445e-b45e-a11eabc1cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Multiple linear regression is a statistical model that uses multiple independent variables to predict a dependent variable.\n",
    "It is an extension of simple linear regression, which uses only one independent variable.\n",
    "The multiple linear regression model is used to find the relationship between the dependent variable and the independent variables.\n",
    "The model is fitted to the data by minimizing the sum of the squared residuals.\n",
    "The coefficients of the model can be interpreted as the change in the dependent variable for a unit change in each independent variable.\n",
    "The main difference between multiple linear regression and simple linear regression is that multiple linear regression uses multiple independent\n",
    "variables to predict the dependent variable. This allows the model to capture more complex relationships between the variables.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80401c8d-6ec7-4cd0-a08d-af081504119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380d20a6-ce1c-475c-9c1b-4c7df5d21587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multicollinearity is a phenomenon in which two or more independent variables in a multiple linear regression model are highly correlated.\n",
    "#This can lead to inaccurate estimates of the regression coefficients and make it difficult to interpret the model.\n",
    "#There are several ways to detect and address multicollinearity, such as using the variance inflation factor (VIF) and removing highly correlated variables from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361bd147-bf9a-4c58-a536-4656efffee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db7375d4-b6e5-4d41-a733-670154e47730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial regression is a type of regression analysis that models the relationship between a dependent variable and one or more independent variables using a polynomial function.\n",
    "# Here are some key differences between polynomial regression and linear regression:\n",
    "\n",
    "#Polynomial regression can model more complex relationships than linear regression.\n",
    "#Polynomial regression requires more data than linear regression.\n",
    "#Polynomial regression is more sensitive to outliers than linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b6dc3-7554-4bf3-aa51-078f0a4a1202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "#regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a87e4d-70d3-4228-ad8b-834127dff3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Here are the advantages and disadvantages of polynomial regression compared to linear regression in 3 lines:\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Can model more complex relationships.\n",
    "More flexible.\n",
    "Disadvantages:\n",
    "\n",
    "Requires more data.\n",
    "More sensitive to outliers.\n",
    "When to use polynomial regression:\n",
    "\n",
    "When the relationship between the dependent variable and the independent variable is nonlinear.\n",
    "When you need a more flexible model.\n",
    "When you have a lot of data.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c417ed6-c4e4-4f26-8187-d96cd89790df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
